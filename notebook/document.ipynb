{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "801de17b",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4d7b397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='ok')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Document Data Structure\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "Document(page_content=\"ok\", metadata={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d56ca718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'example.txt', 'pages': 1, 'author': 'Anshuman', 'date_created': '2026-01-27'}, page_content='this is the main content I am using to create a RAG')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc=Document(\n",
    "    page_content=\"this is the main content I am using to create a RAG\",\n",
    "    metadata={\n",
    "        \"source\": \"example.txt\",\n",
    "        \"pages\": 1,\n",
    "        \"author\": \"Anshuman\",\n",
    "        \"date_created\": \"2026-01-27\"\n",
    "    }\n",
    ")\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cd93097",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create a simple txt File\n",
    "import os\n",
    "os.makedirs('../data/text_files', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce20385c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample txt file created!!!\n"
     ]
    }
   ],
   "source": [
    "sample_text = {\n",
    "    '../data/text_files/python_intro.txt':\"\"\"python programming introduction\"\"\"\n",
    "}\n",
    "for filepath, content in sample_text.items():\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"Sample txt file created!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ab896e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '../data/text_files/python_intro.txt'}, page_content='python programming introduction')]\n"
     ]
    }
   ],
   "source": [
    "### TextLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader('../data/text_files/python_intro.txt', encoding='utf-8')\n",
    "document = loader.load()\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e15318d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../data/text_files/python_intro.txt'}, page_content='python programming introduction'),\n",
       " Document(metadata={'source': '../data/text_files/machine_learning_intro.txt'}, page_content='Machine learning introduction')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Directory Loader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "## load all the text files from the directory\n",
    "dir_loader = DirectoryLoader(\n",
    "    '../data/text_files',\n",
    "    glob='**/*.txt', ## pattern to match the files\n",
    "    loader_cls=TextLoader, ##loader class to use\n",
    "    loader_kwargs={'encoding': 'utf-8'},\n",
    "    show_progress=False\n",
    ")\n",
    "\n",
    "documents=dir_loader.load()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90c3ad8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'xdvipdfmx (20250410)', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-10-03T14:47:38+00:00', 'source': '../data/pdf_files/AnshResume.pdf', 'file_path': '../data/pdf_files/AnshResume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20251003144738Z', 'page': 0}, page_content='Anshuman\\nAspiring Full Stack Developer\\nanshuman302004@gmail.com | +91 9871980990 | Faridabad, Haryana, India\\nlinkedin.com/in/heyansh | github.com/Ansh30a | Portfolio\\nSUMMARY\\nHighly motivated MERN Stack Developer skilled in building scalable full-stack applications using MongoDB,\\nExpress.js, React, and Node.js. Experienced in developing RESTful APIs and integrating third-party services.\\nQuick learner with strong problem-solving and debugging skills.\\nEXPERIENCE\\nMERN Stack Developer Intern\\nJun 2025 – Jul 2025\\nCodec Technologies\\n• Developed full-stack applications using the MERN stack.\\n• Worked on designing and implementing scalable APIs, dynamic user interfaces, and seamless integration\\nbetween back-end and front-end components\\nMERN Stack Developer Intern\\nJun 2024 – Jul 2024\\nManav Rachna Innovation and Incubation Foundation (MRIIF), Faridabad, Haryana\\n• Engineered end-to-end web solutions using MongoDB, Express.js, React.js, and Node.js\\n• Crafted modular APIs and front-end features ensuring consistent data flow and performance\\nTECHNICAL SKILLS\\nLanguages: JavaScript, C++, C, SQL\\nWeb Technologies: HTML, CSS, React.js, Node.js, Express.js\\nDatabases: MySQL, MongoDB\\nTools & Frameworks: Git, GitHub, Vercel, Render\\nSoft Skills: Communication, Problem Solving, Team Collaboration\\nPROJECTS\\nBioDataFlow Platform | Python, MERN\\nLINK\\n• Built full-stack bioinformatics platform with MERN stack + Python Flask serving 100MB+ CSV/TSV\\ndatasets with JWT authentication\\n• Engineered statistical analysis engine processing data points using pandas/scipy/scikit-learn, delivering cor-\\nrelation matrices and basic Statistics with <2s response time\\n• Developed React.js dashboard with Chart.js/D3 visualizations, drag-drop uploads, and responsive UI sup-\\nporting 4 chart types\\n• Deployed to production on Render/Vercel, achieving 99% uptime, implementing rate limiting (100 req/15min),\\nCORS security, and automated health monitoring across 2 microservices\\nPawFect Homes | JavaScript, React, Express.js, Node.js, MongoDB\\nJul 2024\\n• Developed a comprehensive full-stack MERN application designed to simplify pet adoption by connecting\\nusers with shelter animals\\n• Implemented user authentication, real-time pet listings, and secure communication between adopters and\\nshelters\\n• Integrated responsive design principles and interactive interfaces for seamless user experience across devices\\nEDUCATION\\nManav Rachna International Institute Of Research and Studies\\nAug 2022 – Present\\nBachelor of Technology in Computer Science Engineering\\nCGPA: 8.18\\nTRAINING & CERTIFICATIONS\\nWeb Development Essentials – InternShala Trainings\\nDeveloping Secure Software – LinkedIn Learning\\nADDITIONAL INFORMATION\\nLanguages: English (Fluent), Hindi (Native)\\nInterests: Building Personal Projects, Reading Tech Blogs\\nAchievements: Maintained consistent academic performance with 8+ CGPA throughout engineering\\n1')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### PDF files\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "\n",
    "### Directory Loader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "## load all the text files from the directory\n",
    "dir_loader = DirectoryLoader(\n",
    "    '../data/pdf_files',\n",
    "    glob='**/*.pdf', ## pattern to match the files\n",
    "    loader_cls=PyMuPDFLoader, ##loader class to use\n",
    "    show_progress=False\n",
    ")\n",
    "\n",
    "pdf_documents=dir_loader.load()\n",
    "pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f56b646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pdf_documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294abf3b",
   "metadata": {},
   "source": [
    "### Embedding and VectorStoreDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45fc69be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624d28c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using SentenceTransformer\"\"\"\n",
    "    def __init__(self, model_name: str = \"all-miniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initialise the embedding manager\n",
    "\n",
    "        Args:\n",
    "            model_name: HuggingFace model name for sentence embeddings\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the SentenceTransformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model Loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG (uv)",
   "language": "python",
   "name": "rag-uv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
